{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\rl\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import topmost\n",
    "from topmost.data import download_dataset\n",
    "\n",
    "device = \"cuda\" # or \"cpu\"\n",
    "dataset_dir = \"./datasets/20NG\"\n",
    "# download_dataset('20NG', cache_path='./datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0+cu124'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.version\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_size:  11314\n",
      "test_size:  7532\n",
      "vocab_size:  5000\n",
      "average length: 110.543\n"
     ]
    }
   ],
   "source": [
    "########################### Neural Topic Models ####################################\n",
    "# dataset for neural topic models.\n",
    "# For combinedTM, add contextual_embed=True.\n",
    "dataset = topmost.data.BasicDataset(dataset_dir, read_labels=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch in dataset.train_dataloader:\n",
    "#     print(batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 4/200 [00:02<01:29,  2.19it/s]2025-03-28 00:33:58,445 - TopMost - Epoch: 005 loss: 945.663\n",
      "  4%|▍         | 9/200 [00:04<01:14,  2.58it/s]2025-03-28 00:34:00,355 - TopMost - Epoch: 010 loss: 887.170\n",
      "  7%|▋         | 14/200 [00:05<01:10,  2.64it/s]2025-03-28 00:34:02,253 - TopMost - Epoch: 015 loss: 868.479\n",
      " 10%|▉         | 19/200 [00:07<01:08,  2.65it/s]2025-03-28 00:34:04,158 - TopMost - Epoch: 020 loss: 858.299\n",
      " 12%|█▏        | 24/200 [00:09<01:07,  2.62it/s]2025-03-28 00:34:06,092 - TopMost - Epoch: 025 loss: 853.530\n",
      " 14%|█▍        | 29/200 [00:11<01:05,  2.63it/s]2025-03-28 00:34:08,007 - TopMost - Epoch: 030 loss: 850.517\n",
      " 17%|█▋        | 34/200 [00:13<01:02,  2.64it/s]2025-03-28 00:34:09,918 - TopMost - Epoch: 035 loss: 848.172\n",
      " 20%|█▉        | 39/200 [00:15<01:01,  2.64it/s]2025-03-28 00:34:11,821 - TopMost - Epoch: 040 loss: 846.445\n",
      " 22%|██▏       | 44/200 [00:17<00:58,  2.65it/s]2025-03-28 00:34:13,728 - TopMost - Epoch: 045 loss: 844.958\n",
      " 24%|██▍       | 49/200 [00:19<00:56,  2.65it/s]2025-03-28 00:34:15,630 - TopMost - Epoch: 050 loss: 843.731\n",
      " 27%|██▋       | 54/200 [00:21<00:55,  2.65it/s]2025-03-28 00:34:17,536 - TopMost - Epoch: 055 loss: 842.731\n",
      " 30%|██▉       | 59/200 [00:23<00:53,  2.65it/s]2025-03-28 00:34:19,476 - TopMost - Epoch: 060 loss: 841.766\n",
      " 32%|███▏      | 64/200 [00:25<00:51,  2.65it/s]2025-03-28 00:34:21,386 - TopMost - Epoch: 065 loss: 840.764\n",
      " 34%|███▍      | 69/200 [00:26<00:49,  2.62it/s]2025-03-28 00:34:23,311 - TopMost - Epoch: 070 loss: 839.911\n",
      " 37%|███▋      | 74/200 [00:28<00:47,  2.63it/s]2025-03-28 00:34:25,223 - TopMost - Epoch: 075 loss: 839.403\n",
      " 40%|███▉      | 79/200 [00:30<00:45,  2.64it/s]2025-03-28 00:34:27,126 - TopMost - Epoch: 080 loss: 838.575\n",
      " 42%|████▏     | 84/200 [00:32<00:43,  2.66it/s]2025-03-28 00:34:29,029 - TopMost - Epoch: 085 loss: 837.909\n",
      " 44%|████▍     | 89/200 [00:34<00:42,  2.63it/s]2025-03-28 00:34:30,933 - TopMost - Epoch: 090 loss: 837.287\n",
      " 47%|████▋     | 94/200 [00:36<00:40,  2.65it/s]2025-03-28 00:34:32,839 - TopMost - Epoch: 095 loss: 836.709\n",
      " 50%|████▉     | 99/200 [00:38<00:38,  2.66it/s]2025-03-28 00:34:34,745 - TopMost - Epoch: 100 loss: 836.207\n",
      " 52%|█████▏    | 104/200 [00:40<00:36,  2.65it/s]2025-03-28 00:34:36,650 - TopMost - Epoch: 105 loss: 835.685\n",
      " 55%|█████▍    | 109/200 [00:42<00:34,  2.62it/s]2025-03-28 00:34:38,556 - TopMost - Epoch: 110 loss: 835.113\n",
      " 57%|█████▋    | 114/200 [00:44<00:32,  2.65it/s]2025-03-28 00:34:40,462 - TopMost - Epoch: 115 loss: 834.521\n",
      " 60%|█████▉    | 119/200 [00:46<00:30,  2.65it/s]2025-03-28 00:34:42,378 - TopMost - Epoch: 120 loss: 833.915\n",
      " 62%|██████▏   | 124/200 [00:47<00:28,  2.63it/s]2025-03-28 00:34:44,296 - TopMost - Epoch: 125 loss: 833.395\n",
      " 64%|██████▍   | 129/200 [00:49<00:26,  2.63it/s]2025-03-28 00:34:46,208 - TopMost - Epoch: 130 loss: 832.853\n",
      " 67%|██████▋   | 134/200 [00:51<00:25,  2.64it/s]2025-03-28 00:34:48,119 - TopMost - Epoch: 135 loss: 832.276\n",
      " 70%|██████▉   | 139/200 [00:53<00:23,  2.63it/s]2025-03-28 00:34:50,045 - TopMost - Epoch: 140 loss: 831.597\n",
      " 72%|███████▏  | 144/200 [00:55<00:21,  2.58it/s]2025-03-28 00:34:51,997 - TopMost - Epoch: 145 loss: 831.194\n",
      " 74%|███████▍  | 149/200 [00:57<00:19,  2.61it/s]2025-03-28 00:34:53,929 - TopMost - Epoch: 150 loss: 830.555\n",
      " 77%|███████▋  | 154/200 [00:59<00:17,  2.61it/s]2025-03-28 00:34:55,882 - TopMost - Epoch: 155 loss: 830.193\n",
      " 80%|███████▉  | 159/200 [01:01<00:15,  2.63it/s]2025-03-28 00:34:57,787 - TopMost - Epoch: 160 loss: 829.811\n",
      " 82%|████████▏ | 164/200 [01:03<00:13,  2.63it/s]2025-03-28 00:34:59,700 - TopMost - Epoch: 165 loss: 829.400\n",
      " 84%|████████▍ | 169/200 [01:05<00:11,  2.62it/s]2025-03-28 00:35:01,609 - TopMost - Epoch: 170 loss: 828.996\n",
      " 87%|████████▋ | 174/200 [01:07<00:09,  2.65it/s]2025-03-28 00:35:03,522 - TopMost - Epoch: 175 loss: 828.611\n",
      " 90%|████████▉ | 179/200 [01:09<00:07,  2.64it/s]2025-03-28 00:35:05,436 - TopMost - Epoch: 180 loss: 828.275\n",
      " 92%|█████████▏| 184/200 [01:10<00:06,  2.65it/s]2025-03-28 00:35:07,341 - TopMost - Epoch: 185 loss: 827.924\n",
      " 94%|█████████▍| 189/200 [01:12<00:04,  2.65it/s]2025-03-28 00:35:09,247 - TopMost - Epoch: 190 loss: 827.525\n",
      " 97%|█████████▋| 194/200 [01:14<00:02,  2.64it/s]2025-03-28 00:35:11,167 - TopMost - Epoch: 195 loss: 827.317\n",
      "100%|█████████▉| 199/200 [01:16<00:00,  2.64it/s]2025-03-28 00:35:13,072 - TopMost - Epoch: 200 loss: 827.010\n",
      "100%|██████████| 200/200 [01:17<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: max get difference places point really food nice got little welcome mean red noticed anything\n",
      "Topic 1: gun people right police law local guns weapons control get crime kill anti court one\n",
      "Topic 2: god jesus bible believe christian christ church life christians religion faith people say many one\n",
      "Topic 3: subject key interested writes keith eric marc deal alan larry rsa strip literature charles bobby\n",
      "Topic 4: lines center research institute motif based original pittsburgh ray base chicago reference mellon society carnegie\n",
      "Topic 5: window send line lines message display image please screen see advance color look section right\n",
      "Topic 6: like find look real rather stuff make large black little images white sort means cover\n",
      "Topic 7: chip bill robert president house clinton bob package said points chips letter asked asking henry\n",
      "Topic 8: use problem using need help used anyone code work problems ibm build host uses application\n",
      "Topic 9: mail usa card fax newsreader tin bbs cards modem services atheists shipping manual vga crypto\n",
      "Topic 10: writes john apr jim wrote board sun controller paul sound peter tom dan nec reserve\n",
      "Topic 11: drive version windows disk software bit memory hard mac machine drives support mode standard apple\n",
      "Topic 12: distribution dos scsi area ide control mine near colorado running radio self radar wide boulder\n",
      "Topic 13: lines reply pin chris morris split posts adams chemistry hudson ups sub ltd sean victoria\n",
      "Topic 14: new one host state like without old ones two except find school secret possible thing\n",
      "Topic 15: system etc data systems information access type users via internal resource documentation random types user\n",
      "Topic 16: israel jews people turkish war armenian israeli armenians jewish turkey palestinian soviet arab government killed\n",
      "Topic 17: space nasa orbit lunar shuttle moon satellite project program mission research commercial air spacecraft station\n",
      "Topic 18: university host science computer department college texas msg california georgia lab virginia sci tech sciences\n",
      "Topic 19: people like think yes many much dept know things even say true really idea lot\n",
      "Topic 20: good thanks one best way also looking already home top pretty level light man got\n",
      "Topic 21: pub current check entry monitor rules assume change previous jon correct changed values define null\n",
      "Topic 22: inc net general algorithm escrow division corp scott uunet jpeg tim unit gif vms errors\n",
      "Topic 23: internet email faq format gmt anonymous disclaimer newsgroup usenet text originator int sites expressed postscript\n",
      "Topic 24: sale buy money bought sell banks ohio cut sold tax dealer gas rob buying selling\n",
      "Topic 25: get work put time around make back left take place hand try bit enough trying\n",
      "Topic 26: also group part called video used bus usa several model tape made found different thought\n",
      "Topic 27: file windows files graphics run output source server free programs printer unix error user color\n",
      "Topic 28: car cars speed bike price engine road driving oil market ride motorcycle insurance big cost\n",
      "Topic 29: available information list also ftp include number name following questions open current includes based technical\n",
      "Topic 30: two world post high box keys per experience cost low van old problems three germany\n",
      "Topic 31: organization driver drivers also running works installed currently parallel frequently operating regularly riding separately competing\n",
      "Topic 32: water study often medical cause much disease however weight patients effects rate food less problems\n",
      "Topic 33: writes david steve michael mike dave mark brian san frank fbi pat thomas austin bell\n",
      "Topic 34: non encryption subject phone security privacy address access use questions communications des response voice nsa\n",
      "Topic 35: nntp writes please remember univ thank recall rochester forget btw ken daniel wondering address kenneth\n",
      "Topic 36: day just last april end mark days call ago next times james said today smith\n",
      "Topic 37: dod widget serdar batf mon isa simms det eisa btw vlb usr israels xlib doug\n",
      "Topic 38: game team play games hockey nhl season win teams league player baseball toronto bruins players\n",
      "Topic 39: posting info keywords posted bits summary deleted ten hello list average pens cheers watch routines\n",
      "Topic 40: first year years number second long least power period canada serial third total california record\n",
      "Topic 41: think evidence whether question argument fact true say human believe moral reason mean matter know\n",
      "Topic 42: read program set one note time order example give actually write copy reading book return\n",
      "Topic 43: one just now time since see better even question course way point still much far\n",
      "Topic 44: just clipper said got like know right going heard back says think went never started\n",
      "Topic 45: article case opinions news following media discussion building font opinion page trial public joseph according\n",
      "Topic 46: know want sure anyone something maybe someone anyway get else let probably talking contact anything\n",
      "Topic 47: technology computer power engineering corporation earth network software systems computing cable test digital environment mit\n",
      "Topic 48: government public national state law american private states organization federal health administration rights care congress\n",
      "Topic 49: know bad tell sorry say good appreciated western really see friend think richard anybody numbers\n"
     ]
    }
   ],
   "source": [
    "# create a model\n",
    "# model = topmost.ProdLDA(dataset.vocab_size)\n",
    "model = topmost.ETM(dataset.vocab_size, pretrained_WE=dataset.pretrained_WE)\n",
    "# model = topmost.DecTM(dataset.vocab_size)\n",
    "# model = topmost.TSCTM(dataset.vocab_size)\n",
    "# model = topmost.CombinedTM(dataset.vocab_size, dataset.contextual_embed_size)\n",
    "# model = topmost.NSTM(dataset.vocab_size, pretrained_WE=dataset.pretrained_WE)\n",
    "# model = topmost.ECRTM(dataset.vocab_size, pretrained_WE=dataset.pretrained_WE)\n",
    "model = model.to(device)\n",
    "\n",
    "# create a trainer\n",
    "trainer = topmost.BasicTrainer(model, dataset, verbose=True)\n",
    "\n",
    "# train the model\n",
    "top_words, train_theta = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights saved at saved_model\\model_weights.pth\n"
     ]
    }
   ],
   "source": [
    "from utils import save_model, load_model\n",
    "\n",
    "save_model(model)\n",
    "model = load_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from topmost import Preprocess\n",
    "\n",
    "# preprocess = Preprocess()\n",
    "\n",
    "# new_docs = [\n",
    "#     \"This is a new document about space, including words like space, satellite, launch, orbit.\",\n",
    "#     \"This is a new document about Microsoft Windows, including words like windows, files, dos.\"\n",
    "# ]\n",
    "\n",
    "# parsed_new_docs, new_bow = preprocess.parse(new_docs, vocab=dataset.vocab)\n",
    "\n",
    "# # Chuyển đổi sparse matrix sang dense NumPy array\n",
    "# new_bow_dense = new_bow.toarray()  # Hoặc .todense() cũng được\n",
    "\n",
    "# # Chuyển sang PyTorch tensor\n",
    "# new_theta = trainer.test(torch.tensor(new_bow_dense, device=device).float())\n",
    "\n",
    "# print(new_theta.argmax(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "# model = BertModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Câu cần chuyển thành embedding\n",
    "# sentence = \"This is a sentence for embedding using BERT.\"\n",
    "\n",
    "# # Tokenize và tạo tensor đầu vào\n",
    "# inputs = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "# # Lấy embedding từ BERT\n",
    "# with torch.no_grad():\n",
    "#     outputs = model(**inputs)\n",
    "\n",
    "# # Lấy embedding của toàn bộ câu (dùng CLS token hoặc mean pooling)\n",
    "# cls_embedding = outputs.last_hidden_state[:, 0, :]  # Lấy embedding của [CLS] token\n",
    "# mean_embedding = outputs.last_hidden_state.mean(dim=1)  # Trung bình tất cả token\n",
    "\n",
    "# # In kích thước embedding\n",
    "# print(\"CLS embedding shape:\", cls_embedding.shape)  # (1, 768)\n",
    "# print(\"Mean embedding shape:\", mean_embedding.shape)  # (1, 768)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from environment import Environment\n",
    "env = Environment(dataset = dataset, topic_model = model, device = \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing texts: 100%|██████████| 1/1 [00:00<00:00, 999.60it/s]\n",
      "d:\\Anaconda\\envs\\rl\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['doc_embed', 'mean_topic_embeds'])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "### testing environment\n",
    "def get_state_shape(state):\n",
    "    print(state.keys())\n",
    "    for key in state.keys():\n",
    "        print(state[key].shape)\n",
    "state = env.reset()\n",
    "get_state_shape(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing texts: 100%|██████████| 1/1 [00:00<00:00, 661.46it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['file',\n",
       " 'windows',\n",
       " 'files',\n",
       " 'graphics',\n",
       " 'run',\n",
       " 'output',\n",
       " 'source',\n",
       " 'server',\n",
       " 'free',\n",
       " 'programs',\n",
       " 'printer',\n",
       " 'unix',\n",
       " 'error',\n",
       " 'user',\n",
       " 'color',\n",
       " 'quality',\n",
       " 'size',\n",
       " 'multi',\n",
       " 'multiple',\n",
       " 'directory']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.get_k_top_words(\"This is a new document about Microsoft Windows, including words like windows, files, dos.\", testing = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### ENVIRONMENT STATE ###\n",
      "Current time step: 20\n",
      "Document:  david subject real reason politicians want guns organization software support consulting lines politicians want eliminate private ownership guns general public starts tax increases needed fund federal government ever higher percentage tax revenue goes pay interest national currently every tax dollar collected dave beginning look forward reaching taxes pay interest national point federal government business lack funds\n",
      "K-Top words:  ['government', 'public', 'national', 'state', 'law', 'american', 'private', 'states', 'organization', 'federal', 'health', 'administration', 'rights', 'care', 'congress', 'americans', 'policy', 'united', 'free', 'work']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing texts: 100%|██████████| 1/1 [00:00<00:00, 62.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['doc_embed', 'mean_topic_embeds'])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([-15.3566]), True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "done = False\n",
    "while done == False:\n",
    "    state, reward, done = env.step(action = \"windows\")\n",
    "if done:\n",
    "    env.print_current_state()\n",
    "    state = env.reset()\n",
    "\n",
    "get_state_shape(state)\n",
    "reward, done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
