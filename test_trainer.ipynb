{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch\n",
    "import random\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_env:\n",
    "    def __init__(self):\n",
    "        self.state = torch.tensor(data = [0, 0, 0, 0], dtype = torch.float32)\n",
    "        self.action_0_reward = 5\n",
    "        self.action_1_reward = 20\n",
    "        self.action_2_reward = 0\n",
    "\n",
    "        self.minus_pt_prob = 0.1\n",
    "\n",
    "        self.step_counter = 0\n",
    "        self.max_step = 10\n",
    "        self.max_score = self.max_step * max(self.action_0_reward, self.action_1_reward, self.action_2_reward)\n",
    "\n",
    "    def reset(self):\n",
    "        # Reset môi trường trở về trạng thái ban đầu và trả về quan sát đầu tiên\n",
    "        self.state = torch.tensor(data = [0, 0, 0, 0], dtype = torch.float32)\n",
    "        self.step_counter = 0\n",
    "        return self.state\n",
    "    \n",
    "    def step(self, action):\n",
    "        self.step_counter += 1\n",
    "        self.state[action + 1] += 1\n",
    "\n",
    "        if action == 0: # action A -> +5 points\n",
    "            self.state[0] += self.action_0_reward\n",
    "            reward = self.action_0_reward\n",
    "        elif action == 1: # action B -> +20 pts with probs = 0.9, -all otherwise\n",
    "            tmp = random.uniform(0, 1)\n",
    "            if tmp <= 0.1: \n",
    "                reward = -20 #-self.state[0]\n",
    "                self.state[0] = 0\n",
    "            else: \n",
    "                self.state[0] += self.action_1_reward\n",
    "                reward = self.action_1_reward\n",
    "        elif action == 2: # action C -> +0 pts\n",
    "            self.state[0] += self.action_2_reward\n",
    "            reward = self.action_2_reward\n",
    "\n",
    "        done = False\n",
    "        if self.step_counter == self.max_step:\n",
    "            done = True\n",
    "        return self.state, reward, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_policy(nn.Module):\n",
    "    def __init__(self, env, n_hiddens = 5):\n",
    "        super().__init__()\n",
    "        self.env = env\n",
    "        self.fc1 = nn.Linear(4, n_hiddens)\n",
    "        self.fc2 = nn.Linear(n_hiddens, 3)\n",
    "\n",
    "    def normalize(self, state):\n",
    "        state[0] /= self.env.max_score\n",
    "        state[1] /= self.env.max_step\n",
    "        state[2] /= self.env.max_step\n",
    "        state[3] /= self.env.max_step\n",
    "        return state\n",
    "    \n",
    "    def forward(self, state): # state: \n",
    "        state = self.normalize(state).to(device)\n",
    "        h = self.fc1(state)\n",
    "        output = self.fc2(h)\n",
    "        return torch.softmax(output, dim = 0)\n",
    "\n",
    "    def act(self, state):\n",
    "        state = state.float().to(device)\n",
    "        probs = self.forward(state).cpu()\n",
    "        # [0, 1, 2]\n",
    "        # probs = [0.4, 0.2, 0.4]\n",
    "        m = Categorical(probs)\n",
    "        action = m.sample()\n",
    "        return action.item(), m.log_prob(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = My_env()\n",
    "policy = My_policy(env).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from trainer import ReinforceTrainer\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.Adam(params = policy.parameters(), lr = learning_rate)\n",
    "# trainer = ReinforceTrainer(policy, env, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\rl\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mducanh2002add\u001b[0m (\u001b[33mducanh2002add-hanoi-university-of-science-and-technology\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Reinforcement Learning\\rl-ntm\\wandb\\run-20250330_221335-mrx5tgxd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ducanh2002add-hanoi-university-of-science-and-technology/test-project/runs/mrx5tgxd' target=\"_blank\">divine-sun-4</a></strong> to <a href='https://wandb.ai/ducanh2002add-hanoi-university-of-science-and-technology/test-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ducanh2002add-hanoi-university-of-science-and-technology/test-project' target=\"_blank\">https://wandb.ai/ducanh2002add-hanoi-university-of-science-and-technology/test-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ducanh2002add-hanoi-university-of-science-and-technology/test-project/runs/mrx5tgxd' target=\"_blank\">https://wandb.ai/ducanh2002add-hanoi-university-of-science-and-technology/test-project/runs/mrx5tgxd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 10\tAverage Score: 59.00\n",
      "Episode 20\tAverage Score: 72.75\n",
      "Episode 30\tAverage Score: 78.67\n",
      "Episode 40\tAverage Score: 90.88\n",
      "Episode 50\tAverage Score: 97.90\n",
      "Episode 60\tAverage Score: 107.67\n",
      "Episode 70\tAverage Score: 113.79\n",
      "Episode 80\tAverage Score: 116.12\n",
      "Episode 90\tAverage Score: 118.61\n",
      "Episode 100\tAverage Score: 123.45\n",
      "Episode 110\tAverage Score: 133.30\n",
      "Episode 120\tAverage Score: 137.80\n",
      "Episode 130\tAverage Score: 145.10\n",
      "Episode 140\tAverage Score: 145.40\n",
      "Episode 150\tAverage Score: 145.35\n",
      "Episode 160\tAverage Score: 146.00\n",
      "Episode 170\tAverage Score: 146.70\n",
      "Episode 180\tAverage Score: 147.75\n",
      "Episode 190\tAverage Score: 147.45\n",
      "Episode 200\tAverage Score: 143.40\n",
      "Episode 210\tAverage Score: 140.55\n",
      "Episode 220\tAverage Score: 140.85\n",
      "Episode 230\tAverage Score: 142.80\n",
      "Episode 240\tAverage Score: 145.15\n",
      "Episode 250\tAverage Score: 145.85\n",
      "Episode 260\tAverage Score: 143.85\n",
      "Episode 270\tAverage Score: 140.20\n",
      "Episode 280\tAverage Score: 141.50\n",
      "Episode 290\tAverage Score: 143.20\n",
      "Episode 300\tAverage Score: 147.80\n",
      "Episode 310\tAverage Score: 150.95\n",
      "Episode 320\tAverage Score: 154.70\n",
      "Episode 330\tAverage Score: 153.05\n",
      "Episode 340\tAverage Score: 152.30\n",
      "Episode 350\tAverage Score: 154.45\n",
      "Episode 360\tAverage Score: 154.95\n",
      "Episode 370\tAverage Score: 158.70\n",
      "Episode 380\tAverage Score: 158.95\n",
      "Episode 390\tAverage Score: 158.90\n",
      "Episode 400\tAverage Score: 158.05\n",
      "Episode 410\tAverage Score: 156.00\n",
      "Episode 420\tAverage Score: 153.60\n",
      "Episode 430\tAverage Score: 152.55\n",
      "Episode 440\tAverage Score: 153.30\n",
      "Episode 450\tAverage Score: 155.35\n",
      "Episode 460\tAverage Score: 157.20\n",
      "Episode 470\tAverage Score: 155.35\n",
      "Episode 480\tAverage Score: 157.90\n",
      "Episode 490\tAverage Score: 161.10\n",
      "Episode 500\tAverage Score: 161.35\n",
      "Episode 510\tAverage Score: 162.35\n",
      "Episode 520\tAverage Score: 161.95\n",
      "Episode 530\tAverage Score: 161.80\n",
      "Episode 540\tAverage Score: 164.25\n",
      "Episode 550\tAverage Score: 162.80\n",
      "Episode 560\tAverage Score: 164.15\n",
      "Episode 570\tAverage Score: 167.05\n",
      "Episode 580\tAverage Score: 161.05\n",
      "Episode 590\tAverage Score: 159.85\n",
      "Episode 600\tAverage Score: 159.20\n",
      "Episode 610\tAverage Score: 162.05\n",
      "Episode 620\tAverage Score: 164.85\n",
      "Episode 630\tAverage Score: 164.05\n",
      "Episode 640\tAverage Score: 164.20\n",
      "Episode 650\tAverage Score: 163.40\n",
      "Episode 660\tAverage Score: 160.20\n",
      "Episode 670\tAverage Score: 160.50\n",
      "Episode 680\tAverage Score: 164.35\n",
      "Episode 690\tAverage Score: 162.35\n",
      "Episode 700\tAverage Score: 161.95\n",
      "Episode 710\tAverage Score: 159.70\n",
      "Episode 720\tAverage Score: 158.90\n",
      "Episode 730\tAverage Score: 163.05\n",
      "Episode 740\tAverage Score: 159.05\n",
      "Episode 750\tAverage Score: 159.85\n",
      "Episode 760\tAverage Score: 159.45\n",
      "Episode 770\tAverage Score: 158.90\n",
      "Episode 780\tAverage Score: 158.25\n",
      "Episode 790\tAverage Score: 155.85\n",
      "Episode 800\tAverage Score: 157.05\n",
      "Episode 810\tAverage Score: 157.45\n",
      "Episode 820\tAverage Score: 157.70\n",
      "Episode 830\tAverage Score: 154.10\n",
      "Episode 840\tAverage Score: 155.70\n",
      "Episode 850\tAverage Score: 155.30\n",
      "Episode 860\tAverage Score: 154.90\n",
      "Episode 870\tAverage Score: 153.85\n",
      "Episode 880\tAverage Score: 154.25\n",
      "Episode 890\tAverage Score: 156.65\n",
      "Episode 900\tAverage Score: 154.25\n",
      "Episode 910\tAverage Score: 156.65\n",
      "Episode 920\tAverage Score: 156.40\n",
      "Episode 930\tAverage Score: 155.60\n",
      "Episode 940\tAverage Score: 156.00\n",
      "Episode 950\tAverage Score: 156.80\n",
      "Episode 960\tAverage Score: 158.40\n",
      "Episode 970\tAverage Score: 159.60\n",
      "Episode 980\tAverage Score: 158.80\n",
      "Episode 990\tAverage Score: 157.60\n",
      "Episode 1000\tAverage Score: 160.80\n"
     ]
    }
   ],
   "source": [
    "from trainer import reinforce\n",
    "\n",
    "reinforce(policy, env, optimizer, 1000, 20, 1.0, 10, learning_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
